{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ffeafed",
   "metadata": {},
   "source": [
    "Pre-Lecture HW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c609aabd",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1f118c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb49842",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17723620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 391 rows and 11 columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file from the provided URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "num_rows, num_columns = df.shape\n",
    "\n",
    "print(f\"The dataset has {num_rows} rows and {num_columns} columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb9cc43",
   "metadata": {},
   "source": [
    "Observation: An observation refers to a single data point or data entry in a dataset. Each observation has its own row, which includes different kinds of information about it. In terms of the Animal Crossing dataset, each observation is a different villager, and each row contains information on its personality and characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5ee132",
   "metadata": {},
   "source": [
    "Variable: A variable is a single attribute that provides information on each observation. Variables are set as columns. In the Animal Crossing dataset, the different variables describe each villager(observation). The characteristics include the villagers' name, gender, birthday, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc8683",
   "metadata": {},
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a6336c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 391 entries, 0 to 390\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   row_n        391 non-null    int64 \n",
      " 1   id           390 non-null    object\n",
      " 2   name         391 non-null    object\n",
      " 3   gender       391 non-null    object\n",
      " 4   species      391 non-null    object\n",
      " 5   birthday     391 non-null    object\n",
      " 6   personality  391 non-null    object\n",
      " 7   song         380 non-null    object\n",
      " 8   phrase       391 non-null    object\n",
      " 9   full_id      391 non-null    object\n",
      " 10  url          391 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 33.7+ KB\n",
      "\n",
      "\n",
      "Summary Statistics for Numerical Columns:\n",
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "\n",
      "\n",
      "Summary Statistics for Categorical Columns:\n",
      "             id     name gender species birthday personality          song  \\\n",
      "count       390      391    391     391      391         391           380   \n",
      "unique      390      391      2      35      361           8            92   \n",
      "top     admiral  Admiral   male     cat     1-27        lazy  K.K. Country   \n",
      "freq          1        1    204      23        2          60            10   \n",
      "\n",
      "         phrase           full_id  \\\n",
      "count       391               391   \n",
      "unique      388               391   \n",
      "top     wee one  villager-admiral   \n",
      "freq          2                 1   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 391  \n",
      "unique                                                391  \n",
      "top     https://villagerdb.com/images/villagers/thumb/...  \n",
      "freq                                                    1  \n",
      "\n",
      "\n",
      "Count of Unique Values in Each Column:\n",
      "row_n          391\n",
      "id             390\n",
      "name           391\n",
      "gender           2\n",
      "species         35\n",
      "birthday       361\n",
      "personality      8\n",
      "song            92\n",
      "phrase         388\n",
      "full_id        391\n",
      "url            391\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Count of Missing Values in Each Column:\n",
      "row_n           0\n",
      "id              1\n",
      "name            0\n",
      "gender          0\n",
      "species         0\n",
      "birthday        0\n",
      "personality     0\n",
      "song           11\n",
      "phrase          0\n",
      "full_id         0\n",
      "url             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# 1. General Information about the Dataset\n",
    "print(\"Dataset Information:\")\n",
    "df.info()\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Summary Statistics for Numerical Columns\n",
    "print(\"Summary Statistics for Numerical Columns:\")\n",
    "print(df.describe())\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3. Summary Statistics for Categorical Columns\n",
    "print(\"Summary Statistics for Categorical Columns:\")\n",
    "print(df.describe(include='object'))\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4. Count of Unique Values in Each Column\n",
    "print(\"Count of Unique Values in Each Column:\")\n",
    "print(df.nunique())\n",
    "print(\"\\n\")\n",
    "\n",
    "# 5. Checking for Missing Values\n",
    "print(\"Count of Missing Values in Each Column:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75d60e7",
   "metadata": {},
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7464c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (891, 15)\n",
      "\n",
      "Numerical Summary:\n",
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
      "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
      "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "print(\"Shape of the dataset:\", df.shape)\n",
    "\n",
    "# Get the default description (numerical columns)\n",
    "print(\"\\nNumerical Summary:\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9084c042",
   "metadata": {},
   "source": [
    "a) The df.shape function returns the total number of rows and columns in a given dataset. In this Titanic dataset, it returned (891, 15), which means there are 891 rows and 15 columns. However, the df.describe() function will return statistics only on numerical columns, which are columns that include data types int and float. As we can see, out of the 15 total columns in the dataset, df.describe() only returned statistics on 6 of them. The other 9 columns not shown are not numerical, but of a different type such as categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc507f",
   "metadata": {},
   "source": [
    "b) The 'count' value represents how many non-missing entries there are for each column. For example, the 'survived' column has a count value of 891, which is equal to the number of rows in the dataset. However, the count value for the 'age' column is only 714, meaning there are 177 missing entries for this column.The count value helps to spot which columns contain missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b771a",
   "metadata": {},
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d67a48",
   "metadata": {},
   "source": [
    "Attribute: Attributes are similar to variables, in that they store values and information of specific objects. These values include data such as strings, numbers, and lists. Attributes do not end in () and do not take arguments because they can be accessed directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42eaf3d",
   "metadata": {},
   "source": [
    "Method: Methods are functions which perform actions on specific objects. Unlike attributes, methods need to be called upon to perform operations, so they end in () and take arguments. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bbbd07",
   "metadata": {},
   "source": [
    "Post-Lecture HW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50bd466",
   "metadata": {},
   "source": [
    "6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef0059e",
   "metadata": {},
   "source": [
    "Count: The number of non-missing data entries per column in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4005c7e2",
   "metadata": {},
   "source": [
    "Mean: The average of all values in a column. The mean is calculated by adding all the values in a column together, then dividing the sum by the total number of values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43d185",
   "metadata": {},
   "source": [
    "Std (Standard Deviation): The average spread or variance in a dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ce890",
   "metadata": {},
   "source": [
    "Min: The smallest value of a column in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910cc951",
   "metadata": {},
   "source": [
    "25%: The value under which 25% of data entries in a column are found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caca452",
   "metadata": {},
   "source": [
    "50%: The value in which 50% of data entries are found over and 50% of data entries are found under."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c8bf2",
   "metadata": {},
   "source": [
    "75%: The value under which 75% of data entries in a column are found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9639c78",
   "metadata": {},
   "source": [
    "Max: The largest value of a column in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1bf88e",
   "metadata": {},
   "source": [
    "7.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ba2fc6",
   "metadata": {},
   "source": [
    "A case in which using df.dropna() might be peferred over using del df['col'] is when there is a dataset with missing values, and you'd like to only work with complete data. To do this, you would have to remove all rows with missing values so that you can be left with rows without any missing values. Using df.dropna() will do exactly that and remove any row with a missing value. Del df['col'] will only delete a specific column regardless of whether or not it has missing values, and there may still be missing values remaining in other rows. Using it will not help achieve the goal of working only with complete data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c423d4d7",
   "metadata": {},
   "source": [
    "7.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fa863d",
   "metadata": {},
   "source": [
    "A case in which using del df['col'] might be peferred over using df.dropna() is when there is a dataset with multiple columns, and one specific column contains too many missing values for it to be of any use. del df['col'] is able to remove the column so that you are left with all other columns and can continue to use the dataset effectively. Using df.dropna() will remove all rows with missing values, which is not desired in this case. Many columns containing useful data will shrink due to losing the majority of their rows, and it defeats the purpose of trying to keep all other columns intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78675830",
   "metadata": {},
   "source": [
    "7.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f634e90",
   "metadata": {},
   "source": [
    "It can be useful to use del df['col'] before using df.dropna() to minimize the number of data entries lost. When del df['col'] is used first, you can hand pick any columns with large amounts of missing values to delete first. Using df.dropna() after will clean up any remaining missing values and leave you with as many valid data entries as possible. This order helps to avoid deleting entire rows of data, when only a small number of entries in that row were missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a798dd",
   "metadata": {},
   "source": [
    "7.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f64f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (891, 15)\n",
      "\n",
      "Columns in the dataset: ['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone']\n",
      "\n",
      "Description of the dataset:\n",
      "          survived      pclass   sex         age       sibsp       parch  \\\n",
      "count   891.000000  891.000000   891  714.000000  891.000000  891.000000   \n",
      "unique         NaN         NaN     2         NaN         NaN         NaN   \n",
      "top            NaN         NaN  male         NaN         NaN         NaN   \n",
      "freq           NaN         NaN   577         NaN         NaN         NaN   \n",
      "mean      0.383838    2.308642   NaN   29.699118    0.523008    0.381594   \n",
      "std       0.486592    0.836071   NaN   14.526497    1.102743    0.806057   \n",
      "min       0.000000    1.000000   NaN    0.420000    0.000000    0.000000   \n",
      "25%       0.000000    2.000000   NaN   20.125000    0.000000    0.000000   \n",
      "50%       0.000000    3.000000   NaN   28.000000    0.000000    0.000000   \n",
      "75%       1.000000    3.000000   NaN   38.000000    1.000000    0.000000   \n",
      "max       1.000000    3.000000   NaN   80.000000    8.000000    6.000000   \n",
      "\n",
      "              fare embarked  class  who adult_male deck  embark_town alive  \\\n",
      "count   891.000000      889    891  891        891  203          889   891   \n",
      "unique         NaN        3      3    3          2    7            3     2   \n",
      "top            NaN        S  Third  man       True    C  Southampton    no   \n",
      "freq           NaN      644    491  537        537   59          644   549   \n",
      "mean     32.204208      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "std      49.693429      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "min       0.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "25%       7.910400      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "50%      14.454200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "75%      31.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "max     512.329200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "\n",
      "       alone  \n",
      "count    891  \n",
      "unique     2  \n",
      "top     True  \n",
      "freq     537  \n",
      "mean     NaN  \n",
      "std      NaN  \n",
      "min      NaN  \n",
      "25%      NaN  \n",
      "50%      NaN  \n",
      "75%      NaN  \n",
      "max      NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the shape of the dataset\n",
    "print(\"Shape of the dataset:\", df.shape)\n",
    "\n",
    "# Display all the columns in the dataset\n",
    "print(\"\\nColumns in the dataset:\", df.columns.tolist())\n",
    "\n",
    "# Display a description of the dataset\n",
    "print(\"\\nDescription of the dataset:\")\n",
    "print(df.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01a5e3",
   "metadata": {},
   "source": [
    "Above is the dataset before I remove all missing values. There are 15 columns and 891 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "064d0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['deck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207ac474",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52f4f644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived       0\n",
       "pclass         0\n",
       "sex            0\n",
       "sibsp          0\n",
       "parch          0\n",
       "fare           0\n",
       "embarked       2\n",
       "class          0\n",
       "who            0\n",
       "adult_male     0\n",
       "embark_town    2\n",
       "alive          0\n",
       "alone          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c765076d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the cleaned dataset (after removing rows with missing values): (889, 13)\n",
      "\n",
      "Missing values per column after cleanup:\n",
      " survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove all rows with any missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Display the shape of the cleaned DataFrame\n",
    "print(\"Shape of the cleaned dataset (after removing rows with missing values):\", df_cleaned.shape)\n",
    "\n",
    "# Verify that there are no missing values left\n",
    "print(\"\\nMissing values per column after cleanup:\\n\", df_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965f8cc",
   "metadata": {},
   "source": [
    "As seen above, there are now no missing values in this dataset. My approach to removing all missing values was to first remove the 'deck' and 'age' columns, as they had the most missing values out of all the other columns. After removing them, I decided to remove the rows of the last two missing values. \n",
    "\n",
    "I removed the data in this order to minimize the loss of valid data points. If I had used df.dropna() before removing any columns, it would have deleted every row with a missing value, which would leave me with at most 203 rows and only 23% of my data left. By removing the 'deck' and 'age' columns first, I keep the majority of my data. After removing these columns, I was left with just two rows with missing values. I had the option to remove the 'embarked' and 'embark_town' columns, however that would mean I delete 889 valid data entries each. Instead, I can save much more of my data by deleting only the two rows with missing values.\n",
    "\n",
    "After removing all missing values, the dataset now has 13 columns and 889 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90961b30",
   "metadata": {},
   "source": [
    "8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04767df6",
   "metadata": {},
   "source": [
    "df.groupby(\"col1\")[\"col2\"].describe() sorts the dataset into groups by unique values in one column, and then tells descriptive details (such as mean, std, max) for a second column within each group.\n",
    "\n",
    "In this Titanic dataset, I can use this function to group the data by sex, and get further details on the fares paid by each sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9de2d8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>314.0</td>\n",
       "      <td>44.479818</td>\n",
       "      <td>57.997698</td>\n",
       "      <td>6.75</td>\n",
       "      <td>12.071875</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.00</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>577.0</td>\n",
       "      <td>25.523893</td>\n",
       "      <td>43.138263</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>10.5</td>\n",
       "      <td>26.55</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min        25%   50%    75%       max\n",
       "sex                                                                        \n",
       "female  314.0  44.479818  57.997698  6.75  12.071875  23.0  55.00  512.3292\n",
       "male    577.0  25.523893  43.138263  0.00   7.895800  10.5  26.55  512.3292"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"sex\")[\"fare\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b14fe7",
   "metadata": {},
   "source": [
    "By analyzing this data, we can see that the average female had to pay a substantially higher fare than the average male. The max fare for both sexes were the same, however some males were able to board for free while all females had to pay. The 50th and 75th percentile for females were also more than double that for males.\n",
    "\n",
    "Further analysis of this data may be able to provide deep insight on social constructs, sexism, the economy, and more from the time of The Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2286d6",
   "metadata": {},
   "source": [
    "8.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58007351",
   "metadata": {},
   "source": [
    "df.describe() will give counts for all non-missing values in the entire dataset. df.groupby(\"col1\")[\"col2\"].describe() will only include the counts for non-missing values in 'col1', and will be divided into the groups that col1 was split into. It will exclude counts from col2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d15f3b",
   "metadata": {},
   "source": [
    "8.3.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d623155",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5051fd05",
   "metadata": {},
   "source": [
    "For this mistake, I definitely found it easier to fix this issue with ChatGPT. When I presented this error, ChatGPT immediately told me what was wrong, how I can fix the issue, a visual example of the issue, and common issues to check when encountering this error. Everything was well organized and presented in a way that is easy to understand. If I encountered this issue, I think the ChatGPT explanation would help me resolve it fairly quickly and leave me without any questions.\n",
    "\n",
    "Google search is a much different story. The first few results are forum and blog  posts with people publicly asking how to fix this error. The user responses to these posts give quite vague instructions and it is difficult to find a proper solution to this. Compared to asking ChatGPT, it is harder to fix this error by searching on Google."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31c97a5",
   "metadata": {},
   "source": [
    "8.3.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1faade59",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanics.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"titanics.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f0824",
   "metadata": {},
   "source": [
    "Nearly the exact same results from ChatGPT and Google as 8.3.A. For this error, ChatGPT told me to verify the file path, make sure the file exists, correct any typos, and check the working dictionary. As for Google search, the results were forum and blog posts with unclear solutions. ChatGPT provides better troubleshooting help again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029326e",
   "metadata": {},
   "source": [
    "8.3.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56d63fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018b8f18",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDF\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [
    "DF.groupby(\"sex\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a3c3f",
   "metadata": {},
   "source": [
    "For this mistake, ChatGPT and Google were both equally helpful. Results from both mentioned how python is case sensitive, and that it is important to avoid typos and define a varaible correctly. They both included visual examples of the error and solution. Either one of them could effectively help somebody fix this error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c138316f",
   "metadata": {},
   "source": [
    "8.3.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd9baaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misna\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "df.isna.sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2181ef0",
   "metadata": {},
   "source": [
    "In this case, ChatGPT is back to being the much more helpful tool. It explained how this error could come up in different scenariors, such as variable name shadowing and an incorrect use of parantheses. It again showed visual examples of the error and solution, and said that it is important to not misuse parantheses when calling a function. As for Google, the majority of results were forums with unclear advice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa806d42",
   "metadata": {},
   "source": [
    "8.3.E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0b302b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'group_by'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52/1116854187.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'group_by'"
     ]
    }
   ],
   "source": [
    "df.group_by(\"sex\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f0d4a",
   "metadata": {},
   "source": [
    "ChatGPT immediately tells me that the correct spelling for the function is groupby and not group_by, and shows how to use the function correctly. Google yet again only results in forums with many clueless people asking why this happens, with no clear cut solution given by any other users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbdc87e",
   "metadata": {},
   "source": [
    "8.3.F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17bdc386",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SEX'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSEX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAGE\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8875\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SEX'"
     ]
    }
   ],
   "source": [
    "df.groupby(\"SEX\")[\"AGE\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006bdc2c",
   "metadata": {},
   "source": [
    "For this error, neither ChatGPT or Google were very helpful. Google really had nothing to provide, as most people who asked on forums did not receive any answers, or the answers users gave would not exactly fix my exact error. ChatGPT also did not know the exact error or solution, but it did mention using valid parameters. However, that was not its main solution as it mostly talked about how to group columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6eb2ce",
   "metadata": {},
   "source": [
    "8.3.G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fd339f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[43msex\u001b[49m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sex' is not defined"
     ]
    }
   ],
   "source": [
    "df.groupby(sex)[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3c42bf",
   "metadata": {},
   "source": [
    "Yet again, ChatGPT provides far more helpful answers than Google. ChatGPT quickly tells me to the mistake is either because of missing quotations or an undefined variable. Google search results in more forums where users are saying the method to fix this is by using more complicated functions and adding them together. Their answers are confusing and not what I am looking for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924b44f4",
   "metadata": {},
   "source": [
    "9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d9a79d",
   "metadata": {},
   "source": [
    "Yes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0090e9",
   "metadata": {},
   "source": [
    "Summary for the chatbot session used for questions 1-6:\n",
    "\n",
    "Summary of This Chatbot Session\n",
    "In this session, we covered the following topics:\n",
    "\n",
    "Dataset Exploration:\n",
    "\n",
    "You downloaded the \"Animal Crossing characters\" dataset from a URL and wanted to know the number of rows and columns it contains. We discussed how to use Python and the pandas library to find this information.\n",
    "We explored the meanings of \"observations\" (rows) and \"variables\" (columns) in the context of this dataset.\n",
    "You also asked how to create simple summaries of each column in a dataset using Python, for which I provided a script utilizing the pandas functions such as info(), describe(), and others.\n",
    "Differences Between DataFrame Functions:\n",
    "\n",
    "We discussed why there may be a difference in the number of columns reported by df.shape and df.describe(). df.shape shows the total number of rows and columns, while df.describe() only provides summaries for numerical columns by default.\n",
    "I explained the difference in count values found in the summary generated by df.describe(), highlighting that it represents the number of non-missing values for each column.\n",
    "Attributes vs. Methods in Python:\n",
    "\n",
    "You wanted to understand the difference between an attribute function (does not end in ()) and a method function (ends in ()).\n",
    "Attributes represent data or properties of an object, while methods are functions associated with an object that perform actions or operations.\n",
    "Explanation of Statistical Terms:\n",
    "\n",
    "I provided explanations for common statistics (count, mean, std, min, 25%, 50%, 75%, max) generated by the pandas library, detailing what each statistic represents and its purpose in data analysis.\n",
    "This session provided an overview of data exploration and basic statistics using Python, which can help you analyze datasets more effectively.\n",
    "\n",
    "\n",
    "https://chatgpt.com/c/66e0a4fd-bbe4-800c-a38d-a5184bc72b25\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49951eb",
   "metadata": {},
   "source": [
    "Summary of the chatbot session used for questions 7 and 8:\n",
    "\n",
    "Summary of Our Exchanges\n",
    "Difference Between df.dropna() and del df['col']:\n",
    "\n",
    "We discussed the use cases for when df.dropna() is preferred (removing rows with missing values across the entire DataFrame) versus del df['col'] (deleting a specific column from the DataFrame).\n",
    "Combining del df['col'] and df.dropna():\n",
    "\n",
    "We explained how using del df['col'] before df.dropna() can be helpful to remove irrelevant or problematic columns that contain missing data, making the subsequent row-wise removal (dropna) more targeted and effective.\n",
    "Loading the Titanic Dataset:\n",
    "\n",
    "I assisted you with loading the Titanic dataset from a URL using pandas, and we went over how to check the shape of the dataset, display all columns, and provide a description of the dataset.\n",
    "Removing Missing Data:\n",
    "\n",
    "We went over how to remove rows with missing data using df.dropna() and how to display the description of the cleaned dataset.\n",
    "Using groupby with describe():\n",
    "\n",
    "We explained the purpose of df.groupby(\"col1\")[\"col2\"].describe() and provided an example to illustrate how it groups data by one column and provides descriptive statistics for another.\n",
    "Differences in count Values with Missing Data:\n",
    "\n",
    "We covered why count values differ when using df.describe() versus df.groupby(\"col1\")[\"col2\"].describe() in the presence of missing values.\n",
    "Fixing Common Python Errors:\n",
    "\n",
    "NameError: name 'pd' is not defined: Explained how to fix this error by properly importing pandas (import pandas as pd).\n",
    "FileNotFoundError: We discussed how to handle missing file errors by ensuring the correct file path and checking for the existence of the file.\n",
    "NameError: name 'DF' is not defined: We explained how this is likely due to a typo or incorrect capitalization and showed how to correctly define and reference variables.\n",
    "AttributeError: 'function' object has no attribute 'sum': We covered how this error can happen due to name shadowing or incorrect usage of functions and provided examples to resolve it.\n",
    "AttributeError: 'DataFrame' object has no attribute 'group_by': We pointed out the correct method is .groupby(), not .group_by().\n",
    "TypeError(\"You have to supply one of 'by' and 'level'\"): We explained how to fix this error by correctly providing either the by or level parameter when using groupby.\n",
    "NameError: name 'sex' is not defined: We described how this error could occur due to missing quotes around column names or undefined variables and provided solutions to fix it.\n",
    "This summary should cover all the key points we discussed and provide a clear record of our interactions to include in your homework assignment. If you need any more details or clarifications, feel free to ask!\n",
    "\n",
    "\n",
    "https://chatgpt.com/c/66e201f0-926c-800c-acd4-82cda406c664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d6f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
